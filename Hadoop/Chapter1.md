### 初识Hadoop

#### 1.1 数据！数据！
- 个人产生的数据正在快速增长，在不久的将来，个人信息档案将日益普及
- 作为物联网一部分的机器设备产生的数据可能远超个人所产生的数据，如机器日志、RFID读卡器、传感器网络、车载GPS和零售交易数据等
- 组织或企业要想在未来取得成功，不仅需要管理好自己的数据，更需要从其他组织或企业的数据中获取有价值的信息
- “大数据胜于好算法”，对于某些应用（例如根据以往偏好推荐电影和音乐），不论算法多牛，基于小数据的推荐效果往往不如基于大量可用数据的一般算法的推荐效果
- 我们有了大量数据，必须想方设法好好存储和分析这些数据

#### 1.2 数据的存储与分析
- 为了缩短数据的访问时间，可以并行同时从多个硬盘上读写数据
- 需要解决两个问题：
    - 硬件故障问题
    - 大多数分析任务需要以某种方式结合大部分数据来共同完成分析，保证其正确性是很大的挑战
- 针对第一个问题，做常见做法是保存数据的副本，示例冗余磁盘阵列（RAID），Hadoop的分布式文件系统也是一类
- 针对第二个问题，MapReduce提出一个编程模型，该模型抽象出硬盘读/写问题并转换为对一个数据集（由键-值对组成）的计算。计算有map和reduce两部分组成

#### 1.3 查询所有数据
MapReduce是一个批量查询处理器，能够在合理的时间范围内处理针对整个数据集的动态查询

#### 1.4 不仅仅是批处理
- MapReduce并不适合交互式分析，更适合那种没有用户在现场等待查询结果的离线使用场景
- Hadoop的发展已经超越了批处理本身，有时更多被用于指代一个更大的、多个项目组成的生态系统，而不仅仅是HDFS和MapReduce
- 第一个提供在线访问的组件是HBase，一种使用HDFS做底层存储的键值存储模型
- YARN的出现意味着Hadoop有了新处理模型。YARN是一个集群资源管理系统，允许任何一个分布式程序基于Hadoop集群的数据而运行
- 以下是一些能与Hadoop协同工作的处理模式
    - Interactive SQL（交互式SQL）
    - Iterative processing（迭代处理）
    - Stream processing（流处理）
    - Search（搜索）

#### 1.5 相较于其他系统的优势
##### 1.5.1 关系型数据库管理系统
- 为什么不能用配有大量硬盘的数据库来进行大规模数据分析？为什么需要Hadoop？
——寻址时间的提升远远不敌于传输速率的提升，传统的B树（关系型数据库中使用的一种数据结构）受限于寻址的速率
- MapReduce比较适合解决需要以批处理方式分析整个数据集的问题，RDBMS适用于索引后数据集的点查询和更新。MapReduce适合一次写入、多次读取数据的应用，关系型数据库更适合持续更新的数据集
- 关系型数据库和MapReduce的比较

    |       | 传统的关系型数据库 | MapReduce |
    | ----- | :----- | :----- |
    | 数据大小 | GB | PB |
    | 数据存取 | 交互式和批处理 | 批处理 |
    | 更新 | 多次读/写 | 一次写入，多次读取 |
    | 事务 | ACID | 无 |
    | 结构 | 写时模式 | 读时模式 |
    | 完整性 | 高 | 低 |
    | 横向扩展 | 非线性的 | 线性的 |
- 另一个区别在于它们所操作的数据集的结构化程度。结构化数据是RDBMS包括的内容，Hadoop对非结构化或者半结构化数据非常有效，因为它是在处理数据时才对数据进行解释，这种模式在提供灵活性的同时避免了RDBMS数据加载阶段带来的高开销
##### 1.5.2 网格计算
- 高性能计算采用的方法是将作业分散到集群的各台机器上，这些机器访问存储区域网络（SAN）所组成的共享文件系统。这比较适用于计算密集型的作业，如果节点需要访问的数据量更庞大（高达几百GB），很多计算节点就会因为网络带宽的瓶颈问题而不得不闲下来等数据
- Hadoop尽量在计算节点上存储数据，以实现数据的本地快速访问。**数据本地化** 特性是Hadoop数据处理的核心，Hadoop通过显式网络拓扑结构来保留网络带宽，这种排列方式并没有降低Hadoop对计算密集型数据进行分析的能力
- MapReduce这样的分布式处理框架能够检测到失败的任务并重新在正常的机器上执行。无共享（shared-nothing）框架意味着各个任务之间是彼此独立的。相比之下，MPI程序必须显式管理自己的检查点和恢复机制
##### 1.5.3 志愿计算
以SETI@home为例
- 志愿计算项目将问题分成很多快，每一块称为一个**工作单元**，发到世界各地的计算机上进行分析
- 志愿计算问题是CPU高度密集的，比较适合在全球成千上万台计算机上运行，因为计算所花的时间远超过工作单元数据的传输时间，志愿者贡献的是CPU周期，而不是网络带宽
- MapReduce有三大设计目标:
    - 为只需要短短几分钟或几个小时就可以完成的作业提供服务
    - 运行于同一个内部有高速网络连接的数据中心内
    - 数据中心内的计算机都是可靠的、专门的硬件
- 相比之下，SETI@home则是在接入互联网的不可信的计算机上长时间运行，这些计算机的网络带宽不同，对数据本地化也没有要求

#### 1.6 Apache Hadoop发展简史
- Hadoop是Apache Lucene创始人Doug Cutting创建的，Lucene是一个应用广泛的文本搜索系统库。Hadoop起源于开源网络搜索引擎Apache Nutch，后者本身也是Lucene项目的一部分
- Nutch项目开始于2002年，一个可以运行的网页爬取工具和搜索引擎系统很快面世，但后来它的创造者认为这一架构的灵活性不够，不足以解决数十亿网页的搜索问题
- 一篇发布于2003的论文为此提供了帮助，文中描述的是“谷歌分布式文件系统”（GFS）。GFS或类似的架构可以解决他们在网页爬取和索引过程中产生的超大文件的存储需求，更关键的是，GFS能节省系统管理（如管理存储结点）所花的大量时间。2004年，Nutch着手做开源版本的实现，即Nutch分布式文件系统（NDFS）
- 2004年，谷歌发表论文介绍MapReduce系统，2005年初，Nutch开发人员在Nutch上实现了一个MapReduce系统
- 2006年2月，开发人员将NDFS和MapReduce移出Nutch形成Lucene的一个子项目，命名为Hadoop
